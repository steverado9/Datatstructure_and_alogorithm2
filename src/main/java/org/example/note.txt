Data is everything.
No matter the technology you are learning, you are learning it to work with data.
We use programming language to process data
We use database to store data
   What is data structure?
This is a way to organise and store data efficiently.
   When we say efficiently?
we are talking in terms of performance and Memory.
    What are algorithms
Set of instructions to perform a particular task.
    pseudocode
instructions/steps, and they can work on any language.
    Types of data structure
we have different types of data structure , but we need to understand when to use what.
That is use a proper algorithm with a proper data structure.
    Data
A variable is used to store data and the variable will have a type.
Data types: the type of data a variable is storing/holding. and there are system defined data types called primitive data types.
complex data types eg class
There are user defined data type.
    Abstract data type
This is when you have a concept and operations to it and it has data in it.
Meaning we can create our own data types and operations it can take.
    Arrays
Instead of storing different values in different variables,
We can store all the values in a single variable called "Array".
eg
int[] numbers = {5, 4, 3, 2, 1}
This data will be stored in a memory
And every memory will have a memory location
for primitive data,
anytime we need the data, the program will jump to the memory location by searching for the address to get it.
but for arrays,
once the first element is stored in, it takes an index of 0. To get the rest element, you just have to add 1 to it.
    Operations on an array
1)Read operation: we use the arrayname[index], the computer will just use the memory address.
This is a fast operation cos the computer already knows the memory location of the array and it uses the index to get the data.
2)Search operation: In searching, we are not using the index and the computer doesnt know where the element is without the index.
So we basically have to search each element.
3)Insert operation: inserting at the end, We have to get the size of the array and add to +1 of the index.
Inserting in between values: we have to create a new block at the end of the array and start moving the elements one by one till there is space to add inbetween.
4)Deleting operation: deleting at the end is also faster.
deleting in between will take alot of time cos you have to move the elements one by one and that depends on the number of elements in the array.
    Algorithm
The number of steps your code takes to perform the operation determines the time complexity.
A good algorithm should be time efficient.
The steps to solve a problem is called algorithm.
To solve a problem, we have multiple solutions, but we have to pick the best one.
The best one is the one that is less time-consuming.
The best one in this sense is the one that takes less memory or less time.
    Algorithm analysis
This is a way to make your algorithm more efficient
As a developer, you must make sure first you application works, then you now optimize it.
You can optimize in two ways
1)Space complexity: an algorithm that use less memory
2)Time complexity: an algorithm that takes less time.
    How to use linear and binary search
1)search an element in a sorted array
we will use two solutions
-linear search
we go through the elements one by one and compare them with our target element.
best case scenario, we are searching for an element at the beginning of our array, this will take one step
worse case scenario, the element we are searching for is at the end, our steps will be in proportion with our array size.
That is as your size increases, our number of steps to solve this problem increases too
-binary search
In binary search, we divide our array into two parts i.e. find the mid-value
middle value = (start position - end position) / 2
first check if the value you are searching for is the mid value
if no check if it is less than the mid value
if yes, our mid is now our end value and we will now divide the array into two using the mid value as the new end value
check again if the mid value is the value you are searching for
In worse case scenarios, binary search is faster than linear search.
The binary search time complexity is not constant with increasing input and it is number of steps do not increase with the number of input so it is O(log n) Logarithmic Time.
    Time complexity
This is the measure of how the running time of an algorithm increases with the size of the input data.
    How to calculate time complexity
We use Big O Notation to understand the time complexity of an algorithm.
-O(1): Constant Time
-O(log n): Logarithmic Time
-O(n): Linear Time
-O(n log n): linearithmic Time
-O(n^2): Quadratic Time
-O(2^n): Exponential Time
-O(n!): Factorial Time
    constant time Big O(1)
searching for a particular element in an array using its index is always done at constant time
No matter the number of inputs, as long as you use the index to search for an element,the time is always constant.
As long as the algorithm takes the same number of steps, no matter the size of the input we say it is done at constant time.
    worse case scenario: what if the element we are looking for is at the end of the array
That means as our array size increases, the number of steps also increases that will be Big O(n), n = number of elements in the array ie linear time
Whenever building an algorithm, make sure it is between
-O(1): Constant Time
-O(log n): Logarithmic Time
-O(n): Linear Time
or else the application will struggle with increased number of input.
    Practical implementation of linear search O(n) and binary search O(log n)
We will have a list of element and we want to search for a particular element.
    Sorting techniques
we have diffrent types, some of them are
-Bubble sort
-Insertion sort
-Quick sort
-selection sort
-Merge sort
-Radix sort
-Heap sort
-Bucket sort
    Bubble sort
This is not efficient, but it is easy to understand.
You will compare two values at a time and then you will try to swap them
continue the iteration till you sort them
The time complexity is O(n^2) cos we have to use two loops, so it is not very efficient
The outer loop is responsible for the number of iteration and the inner loop is responsible for swapping.
    selection sort
In this type of sort, you find the minimum or maximum value and you make sure it stay at the start or end and the value there will swap position with it.
We will find the second minimum or maximum value, and we will send it to the second end or second begining and sawp the  value previously there
The time complexity is also O(n^2)
    Insertion sort
This method just takes the element and put them at the right location.
We do not use swapping here, we use shifting
The time complexity for this algorithm is Big O(n^2)
    Quick sort
The time complexity for this algorithm in the best case is O(n log(n)) and in the worse case is O(n^2).
We do this using divide and conquer i.e we separate our problems and solve them separately then join them together.
It also works with recursion
recursion: calling a function by itself.
pivot: This is a central point of a problem
Tree: When we divide our problems into subsections, we are creating a tree structure.
    Divide and conquer technique
We divide first, we conquer and then we combine
i.e we break the problems into subsections, we will apply the algorithm on each subsections and then we get a solution for each subsections and then you will merge to get your desired result.
    Tree Structure
That is a root element and branches from the root element.
    Recursion
A function is used to achieve a particular task.
eg print, search, add2numbers, processPayment, all this happens with the help of functions.
A function calling itself is called recursion.
recursion can serve as a loop, all you have to do is add a condition so it can stop.
example of a recursion is "find a factorial".
    Merge sort
This has a time complexity of O(n log(n)).
This also follows the divine and conquer technique.
The difficult part here is the merging.
In this technique, we use the middle number i. the median
median = (left index + right index)/ 2
we use the median to divide the array into two
from 0 - median and from after median to last index.
You will divide the sub arrays into two again using the median
you will continue dividing till you get individual values.
after getting individual values, we conquer(sort the values)
since they are single values, they are already sorted
Then we merge
But before merging, you compare the values
    Linked list
In linked list, the values are stored in a node.
and the node takes a value(data) and an address(reference of the next node)
The address stores a reference of the next node.
what this does is that it links the nodes
That is why it is called a linked list.
Linklist have a list of values that are linked.
We have inbuilt linklist in java and we can also create our own linkedlist class.
    How to insert a new value in a linklist
From the end
-first create a new node
-put a value and make the address will be null
-then link it to the previous last element using the address so our new address will be the new last element.
    Head
Every link list have a head
The head is a reference which is pointing to the first location(node)
    Insert in between in a linklist
-create a new node, it takes a value and an address
-we will change the address of the middle value to the address of the new node created
-And the address of the new node will be the address of the element after the middle value
    How to remove a value in a linklist
The address linking to the element you want to remove, change it to reference another node and the node without an address linking to it will be garbage collected.
    Singly linked list
This is a link list that only goes one way like the one we are talking about above.
    doubly link list
Every node in this list will have two addresses and a value.
The first node will have an address of null, a value and an address pointing to the next node.
The last node will also have an address pointing to the previous node, a value and null.
In this type of list, you can go forward and backward.

    Stack
This is a linear data structure, and it is used to store data.
This is an inbuilt class in java.
Stack follows the "last in first out"(LIFO) principle.
In stack, you have only one entry point and the same entry point is the exit point.
When we want to insert data, we use push
When we want to get data, we use pop
When the stack is full, and you try to push(insert element) in it, you get an error "Overflow" i.e, stack overflow.
When the stack is empty, and you try to pop(get element) in it, you get a stack underflow error.
We use "Peek" to see the last value in the stack. It will not remove it
    We can implement stack in two ways
Using Arrays or Linkedlist.

    Queue
This data structure follows the "first in first out"(FIFO) principle.
Enqueue - This means to insert data.
Dequeue - This means to remove data.
peek - This gives you the value of the element to deque but not remove it.
circular queue
Example of queue, A todo list.

    Tree
In tree, we create different nodes with tree structure.
    Tree Terminologies
-Node: Node is somewhere you will put your data, and it will also have a reference for the next element.
-Root: The node at the top level is the root node.
-Parent: The root node ie node with no parent.
-Child: branch of the root node or branch of any node.
-Edge: The line that connects the parent and child.
-Leaf node: This is a child node that will be only child, i.e it cannot be a parent.
-Depth: The number of edge you have to pass to get to a child node.
-Height: This is the highest depth to get to a child node.
-Subtree: A tree from a parent tree.
    Binary tree
This tree has the maximum number of child node of two.
That is, the child node can be zero, one or two.
    Type of Binary Tree
1)Binary Search Tree: If you want to search up an element in a Binary tree, it is better to save it in a binary search tree.
    Tree Traversal
There are 3 ways to transverse through a tree
1)In order traversal: You first go to the left, then you go to the root and then you go to your right.
2)Pre order traversal: here you first go to the root, the you go to the left and then you go to the right.
3)Post order traversal: here you go to the left then right then root.
The difference between this 3 is the way you print your root node.